1. Need to create the GRPC service for pushing/ retrieving data. - DONE
2. Hook it up to an ASP.NET program. -- via the dependency injection mechanism
3. Create a docker image from that guy
4. Deploy it as part of Kubernetes

Attach pods


Generate the GRPC client for the storage adapter
Write the side car logic:
    -> GRPC server for processing a request coming from the orchestrator
    -> GRPC client for sending a request to the storage adapter

GRPC definition for SideCar <-> Compute step communication
GRPC client for calling into the Orchestrator to signal data avaialble.


Orchestrator logic:
    Sends a request to one of the compute steps


For the first implemenentation:
    1. A single file as input is being processed.
    2. Compute step 1. Adds one line to the file: "First step was here!"
    3. Compute step 2. Adds another line to the file: "Second step was here!"
    4.


Communication can only happen through point to point communication

Transport can be:
    grpc
    rest api
    message queue. 


Compute steps basically need to implement a GRPC interface the way they see fit.

Define the IDLs for the communication in between services.


Communication: synchronous or asynchronous? 
    Async will lead to better scalability. But can I actually prove it?
        Load test?
        
I can use the Protobuf IDL to operate streams:

1. Stream-splitter for the stream that only does splitting of the stream.
2. Multiple consumer waiting for the stream splitter to operate.
This can be done at multiple levels. The fact that the logic is injected in the compute stream is super useful (they can do clustering on the streams)

One fundamental challenge is the inter-container communication - how do you ensure the overhead is kept to a minimum?

