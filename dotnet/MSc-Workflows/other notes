Need to gather the data from the logs and from Jaeger query service:


For the logs:

Can get a csv:

from, to, payload.

    Computing continuum fallback - when data locality is enabled.

    Reducing the data trasnfer in general and especially in edge -> cloud communication.
        Data Locality on vs off.


From Jaeger
    I want a piechart with where time is spent for 1 particular DataAvailableEvent. 
    
    From the time the orchestrator is made aware of a new data chunk being available to the moment the output of the step is fully registered and ready to trigger the next step.

    (or average trace visualized in Jaeger UI)


For End2End numbers:
    For an example workflow.
    What is the throughput
    What is the end2end execution time.


The fact that the code is already is instrumented is a good enough artifact to mention in the thesis.


TODO 01.04.2021:
    DONE - Data locality with Host and Zone - explicit through the GRPC contract
    DONE - Attach size of the request to current activity as a tag to the GRPC request
    DONE - Write the script to output csvs with the experimental data.
    DONE - Write deploy.sh for the multizone thingy
    DONE - Publish the images to dockerhub
    DONE - Multi-zone deployments/ daemonsets.
    DONE - Archive traces in Jaeger.
    DONE - Write bash scripts to run the experiments and gather the data    
    DONE - Delete data after use to save storage space.
    DONE - Write pandas python code to draw the visualizations of the data.
    DONE Classify the experiments based on the cluster / workflow needs.
    DONE Test the analysis pipeline E2E with Kind.

    Add 5 different data sizes for Hard linking
    More iterations on connection pooling.
    Cold Start
    Add a few more iterations on everything.

    Set up Kubernetes in Azure. Edge1 and Edge2 are availability zones, Cloud1 is a different zone.

    Write the thesis/experiment contents.
    Learn a bit of Airflow.



My public IP; 84.213.194.235
Kubernetes port : 6443