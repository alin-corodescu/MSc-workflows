- Execution time and network bandwidth utilization are two important indicators often measured in big data systems.

- Big data workloads are always happening in a distributed system, with data and processing spread across machines
- The network traffic generated by the transfer of data so it can be processed is significant for the performance and bandwidth utilization
    - Thus in systems with data-intensive workloads, data locality is a key aspect
    - Computing continuum also helps by bringing the computation closer to the data to avoid these expensive transfers.

- As with any distributed system, besides the data transfer, some control-flow communication also needs to happen between the different components
    - This communication also needs to be efficient and performant to ensure scalability.

- In recent works, software containers are used more and more in the big data systems because of the benefits they provide:
    - Easier separation of individual components 
    - Isolation, dependency management, lightweight virtualization
    - Flexibility to use different technologies to store and process data.

- It's important to take the optimization work done in the area and translate and adapt it to container-centric solutions.
    - The current work is targeted workflow system developers and aims to provide insights into better understanding the implications (in terms of optimization but also the alignment with the other desirable traits of container-centric system) of the presented architectural and technology-specific approaches.
        - Use/ extrapolate from the experiment data presented here to empower more informed design/ implementation decisions, adjusted to each individual use-case.

    - Data locality in other works, if present at all, breaks the separation of concerns and requires a lot of intervention from the workflow designer....
        - TODO i need to add more stuff about related works here.

    - The thesis proposes a novel approach for handling data locality as a first class citizen in container-centric sytems:
        - The proposed approach while also maintaining the benefits the container-based solution provides (separation of concerns, isolation, flexibility of used technologies)
        - Hidden from the worfkflow/ step designer.
        - TODO should I go into details about how this will be achieved exactly - data system, etc.


    - As part of the implemetantion showcasing the approach mentioned above, the current work also analyzes the effect of technology-specific approaches for optimizing containerized workflows in general:

        - possibly higher communication overhead as different components can no longer be in the same process - e.g. compute step logic communicating with the orchestrator
            - as part of the implementation of the thesis, we evaluate [binary serialization + GRPC vs JSON-serialization + REST] as potential approaches for communication protocols
            - the analysis of these choices id done from the perspective of their alignment with the benefits provided by container-centric architecture (flexibility, programming language agnostic etc.) and execution time + bandwidth consumption.

        - the overhead of managing the lifecycle of containers.
            - the work in this thesis studies two different approaches for managing the lifecycle of containers 
                - one where each container is created to process a unit of data and then discarded once done
                - another where containres are  re-used to process multiple units of data, such that the cost of instantiating containers, albeit low, is not incurred for every unit of data.
    
    - Data locality, efficient communication and shared containers have been studied in isolation and the current work aims to place them and measure the benefit in containerized big data workflow systems.


- Design and implementation chapter will explictly describe the implementation, by referencing back to the items above.

- To validate our assumptions, we are experimenting with the proposed architecture and implementation to highlight the benefits of the proposed approaches.
- Isolated experiments - how much the approach helps in a isolation vs how much it helps in an E2E run. For example, using GRPC may improve the performance compared to REST, but in the E2E execution time / bandwidth picture these numbers may be insignifiant.